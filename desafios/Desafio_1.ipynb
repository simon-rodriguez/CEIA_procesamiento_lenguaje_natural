{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "ftPlyanuak8n",
        "outputId": "45a94d0e-49e7-4f7c-c806-7d5b66779dd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "dcca5de6-dac1-4d68-d284-ce7be2ed9e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "95111464-e40c-4b57-d154-ede153739a82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "47438"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# una vez fiteado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['house']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "93d09f31-4c42-4215-e750-a13c83ecf96a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "59799046-9799-406f-c4be-81c5765de58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "b2bd8485-40c7-4923-c8a9-4ad6b735576e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive-name: space/net\n",
            "Last-modified: $Date: 93/04/01 14:39:15 $\n",
            "\n",
            "NETWORK RESOURCES\n",
            "\n",
            "OVERVIEW\n",
            "\n",
            "    You may be reading this document on any one of an amazing variety of\n",
            "    computers, so much of the material below may not apply to you. In\n",
            "    general, however, systems connected to 'the net' fall in one of three\n",
            "    categories: Internet, Usenet, or BITNET. Electronic mail may be sent\n",
            "    between these networks, and other resources available on one of these\n",
            "    networks are sometimes accessible from other networks by email sent to\n",
            "    special 'servers'.\n",
            "\n",
            "    The space and astronomy discussion groups actually are composed of\n",
            "    several mechanisms with (mostly) transparent connections between them.\n",
            "\n",
            "    One mechanism is the mailing list, in which mail is sent to a central\n",
            "    distribution point which relays it to all recipients of the list. In\n",
            "    addition to the general lists for space (called SPACE Digest for\n",
            "    Internet users, and SPACE on BITNET), there are a number of more\n",
            "    specialized mailing lists described below.\n",
            "\n",
            "    A second mechanism is Usenet 'netnews'. This is somewhat like a bulletin\n",
            "    board operating on each system which is a part of the net. Netnews\n",
            "    separates contributions into hundreds of different categories based on a\n",
            "    'group name'. The groups dealing most closely with space topics are\n",
            "    called 'sci.space.news', 'sci.space', 'sci.space.shuttle', 'sci.astro',\n",
            "    and 'talk.politics.space'. Contributors 'post' submissions (called\n",
            "    'articles' in netnews terminology) on their local machine, which sends\n",
            "    it to other nearby machines. Similarly, articles sent from nearby\n",
            "    machines are stored locally and may be forwarded to other systems, so\n",
            "    that an article is posted locally and eventually reaches all the Usenet\n",
            "    sites interested in receiving the news group to which the article was\n",
            "    posted.\n",
            "\n",
            "    Gateway machines redirect the Usenet sci.space group into Internet and\n",
            "    BITNET mailing lists and vice versa; the other Usenet groups are not\n",
            "    accessible as mailing lists. If you can receive netnews, its more\n",
            "    flexible interface and access to a wider range of material usually make\n",
            "    it the preferred option.\n",
            "\n",
            "MAILING LISTS\n",
            "\n",
            "    SPACE Digest is the main Internet list, and is now being run by the\n",
            "    International Space University (in only its second change of management\n",
            "    in over a decade). Email space-request@isu.isunet.edu (message body\n",
            "    should be in the format 'subscribe space John Public') to join. Note\n",
            "    that the moderated SPACE Magazine list is defunct at present for lack of\n",
            "    a moderator. Old copies of SPACE Digest since its inception in 1981 are\n",
            "    available by anonymous FTP. Retrieve\n",
            "\tjulius.cs.qub.ac.uk:pub/SpaceDigestArchive/README\n",
            "    for further details.\n",
            "\n",
            "    Elements is a moderated list for fast distribution of Space Shuttle\n",
            "    Keplerian Elements before and during Shuttle flights. NASA two line\n",
            "    elements are sent out on the list from Dr. Kelso, JSC, and other sources\n",
            "    as they are released. Email to elements-request@telesoft.com to join.\n",
            "\n",
            "    GPS Digest is a moderated list for discussion of the Global Positioning\n",
            "    System and other satellite navigation positioning systems. Email to\n",
            "    gps-request@esseye.si.com to join.\n",
            "\n",
            "    Space-investors is a list for information relevant to investing in\n",
            "    space-related companies. Email Vincent Cate (vac@cs.cmu.edu) to join.\n",
            "\n",
            "    Space-tech is a list for more technical discussion of space topics;\n",
            "    discussion has included esoteric propulsion technologies, asteroid\n",
            "    capture, starflight, orbital debris removal, etc. Email to\n",
            "    space-tech-request@cs.cmu.edu to join. Archives of old digests and\n",
            "    selected excerpts are available by anonymous FTP from\n",
            "    gs80.sp.cs.cmu.edu (128.2.205.90) in /usr/anon/public/space-tech,\n",
            "    or by email to space-tech-request if you don't have FTP access.\n",
            "\n",
            "    SEDS-L is a BITNET list for members of Students for the Exploration and\n",
            "    Development of Space and other interested parties. Email\n",
            "    LISTSERV@TAMVM1.BITNET with a message saying \"SUBSCRIBE SEDS-L your\n",
            "    name\". Email saying \"INDEX SEDS-L\" to list the archive contents.\n",
            "\n",
            "    SEDSNEWS is a BITNET list for news items, press releases, shuttle status\n",
            "    reports, and the like. This duplicates material which is also found in\n",
            "    Space Digest, sci.space, sci.space.shuttle, and sci.astro. Email\n",
            "    LISTSERV@TAMVM1.BITNET saying \"SUBSCRIBE SEDSNEWS your name\" to join.\n",
            "    Email saying \"INDEX SEDSNEWS\" to list the archive contents.\n",
            "\n",
            "    Ron Baalke (baalke@kelvin.jpl.nasa.gov) runs a mailing list which\n",
            "    carries the contents of the sci.space.news Usenet group. Email him\n",
            "    to join the list.\n",
            "\n",
            "    As a general note, please mail to the *request* address to get off a\n",
            "    mailing list. SPACE Digest, for example, relays many inappropriate\n",
            "    'please remove me from this list' messages which are sent to the list\n",
            "    address rather than the request address.\n",
            "\n",
            "PERIODICALLY UPDATED INFORMATION\n",
            "\n",
            "    In addition to this FAQ list, a broad variety of topical information is\n",
            "    posted to the net (unless otherwise noted, in the new group\n",
            "    sci.space.news created for this purpose). Please remember that the\n",
            "    individuals posting this information are performing a service for all\n",
            "    net readers, and don't take up their time with frivolous requests.\n",
            "\n",
            "    ACRONYMS\n",
            "\tGarrett Wollman (wollman@UVM.EDU) posts an acronym list around the\n",
            "\tfirst of each month.\n",
            "\n",
            "    ASTRO-FTP LIST\n",
            "\tVeikko Makela (veikko.makela@helsinki.fi) posts a monthly list of\n",
            "\tanonymous FTP servers containing astronomy and space related\n",
            "\tmaterial to sci.space and sci.astro.\n",
            "\n",
            "    AVIATION WEEK\n",
            "\tHenry Spencer (henry@zoo.toronto.edu) posts summaries of\n",
            "\tspace-related stories in the weekly _Aviation Week and Space\n",
            "\tTechnology_.\n",
            "\n",
            "    BUYING TELESCOPES\n",
            "\tRonnie Kon (ronnie@cisco.com) posts a guide to buying telescopes to\n",
            "\tsci.astro.\n",
            "\n",
            "    ELECTRONIC JOURNAL OF THE ASA\n",
            "\tDon Barry (don@chara.gsu.edu) posts the monthly Electronic Journal\n",
            "\tof the Astronomical Society of the Atlantic to sci.astro.\n",
            "\n",
            "    FLIGHT INTERNATIONAL\n",
            "\tSwaraj Jeyasingh (sjeyasin@axion.bt.co.uk) posts summaries of\n",
            "\tspace-related news from _Flight International_. This focuses more on\n",
            "\tnon-US space activities than Aviation Week.\n",
            "\n",
            "    LARGE ASTRONOMICAL PROJECTS\n",
            "\tRobert Bunge (rbunge@access.digex.com) posts a list describing many\n",
            "\t\"Large Telescope Projects Either Being Considered or in the Works\"\n",
            "\tto sci.astro.\n",
            "\n",
            "    NASA HEADLINE NEWS & SHUTTLE REPORTS\n",
            "\tPeter Yee (yee@ames.arc.nasa.gov) posts a variety of NASA material,\n",
            "\tincluding NASA Headline News (with the schedule for NASA SELECT),\n",
            "\tshuttle payload briefings and flight manifests, and KSC shuttle\n",
            "\tstatus reports. For Usenet users, much of this material appears in\n",
            "\tthe group sci.space.shuttle.\n",
            "\n",
            "    NASA UPDATES\n",
            "\tRon Baalke (baalke@kelvin.jpl.nasa.gov) posts frequent updates from\n",
            "\tJPL, Ames, and other centers on the Ulysses, Gailileo, Pioneer,\n",
            "\tMagellan, Landsat, and other missions.\n",
            "\n",
            "    ORBITAL ELEMENT SETS\n",
            "\tTS Kelso (tkelso@blackbird.afit.af.mil) posts orbital elements from\n",
            "\tNASA Prediction Bulletins.\n",
            "\n",
            "\tMike Rose (mrose@stsci.edu) posts orbital elements for the Hubble\n",
            "\tSpace Telescope to sci.astro.\n",
            "\n",
            "\tJost Jahn (j.jahn@abbs.hanse.de) posts ephemerides for asteroids,\n",
            "\tcomets, conjunctions, and encounters to sci.astro.\n",
            "\n",
            "    SATELLITE LAUNCHES\n",
            "\tRichard Langley (lang@unb.ca) posts SPACEWARN Bulletin, which\n",
            "\tdescribes recent launch/orbital decay information and satellites\n",
            "\twhich are useful for scientific activities. Recent bulletins are\n",
            "\tavailable by anonymous FTP from nssdca.gsfc.nasa.gov in\n",
            "\tANON_DIR:[000000.ACTIVE.SPX].\n",
            "\n",
            "    SHUTTLE MANIFEST\n",
            "\tKen Hollis (gandalf@pro-electric.cts.com) posts a compressed version\n",
            "\tof the Space Shuttle launch manifest to sci.space.shuttle. This\n",
            "\tincludes dates, times, payloads, and information on how to see\n",
            "\tlaunches and landings.\n",
            "\n",
            "    SOLAR ACTIVITY\n",
            "\tCary Oler (oler@hg.uleth.ca) posts Solar Terrestrial reports\n",
            "\t(describing solar activity and its effect on the Earth) to\n",
            "\tsci.space. The report is issued in part from data released by the\n",
            "\tSpace Enviroment Services Center, Boulder Colorado. The intro\n",
            "\tdocument needed to understand these reports is available by\n",
            "\tanonymous FTP from solar.stanford.edu (36.10.0.4) in\n",
            "\tpub/understanding_solar_terrestrial_reports. nic.funet.fi\n",
            "\t(128.214.6.100) also has this document in\n",
            "\t/pub/misc/rec.radio.shortwave/solarreports and is an archive site\n",
            "\tfor the reports (please note this site is in Europe, and the\n",
            "\tconnection to the US is only 56KB). A new primary archive site,\n",
            "\txi.uleth.ca (142.66.3.29), has recently been established and will be\n",
            "\tactively supported.\n",
            "\n",
            "    SOVIET SPACE ACTIVITIES\n",
            "\tGlenn Chapman (glennc@cs.sfu.ca) posts summaries of Soviet space\n",
            "\tactivities.\n",
            "\n",
            "    SPACE ACTIVIST NEWSLETTER\n",
            "\tAllen Sherzer (aws@iti.org) posts a newsletter, \"One Small Step for\n",
            "\ta Space Activist,\" to talk.politics.space. It describes current\n",
            "\tlegislative activity affecting NASA and commercial space activities.\n",
            "\n",
            "    SPACE EVENTS CALENDAR\n",
            "\tRon Baalke (baalke@kelvin.jpl.nasa.gov) posts a calendar including\n",
            "\tanniversaries, conferences, launch dates, meteor showers and\n",
            "\teclipses, and other space-related events.\n",
            "\n",
            "    SPACE NEWS\n",
            "\tJohn Magliacane (kd2bd@ka2qhd.UUCP) posts \"SpaceNews\" (covering\n",
            "\tAMSATs, NOAA and other weather satellites, and other ham\n",
            "\tinformation) to rec.radio.amateur.misc and sci.space.\n",
            "\n",
            "    SPACE REPORT\n",
            "\tJonathan McDowell (mcdowell@cfa.harvard.edu) posts \"Jonathan's Space\n",
            "\tReport\" covering launches, landings, reentries, status reports,\n",
            "\tsatellite activities, etc.\n",
            "\n",
            "    TOWARD 2001\n",
            "\tBev Freed (freed@nss.fidonet.org) posts \"Toward 2001\", a weekly\n",
            "\tglobal news summary reprinted from _Space Calendar_ magazine.\n",
            "\n",
            "\n",
            "WARNING ABOUT NON-PUBLIC NETWORKS\n",
            "\n",
            "    (Included at the suggestion of Eugene Miya, who wrote the item)\n",
            "\n",
            "    NASA has an internal system of unclassified electronic mail and bulletin\n",
            "    boards. This system is not open for public use. Specifically, NASA\n",
            "    personnel and procurement operations are regarded with some sensitivity.\n",
            "    Contractors must renegotiate their contracts. The Fair and Open\n",
            "    Procurement Act does not look kindly to those having inside information.\n",
            "    Contractors and outsiders caught using this type of information can\n",
            "    expect severe penalities. Unauthorized access attempts may subject you\n",
            "    to a fine and/or imprisonment in accordance with Title 18, USC, Section\n",
            "    1030. If in fact you should should learn of unauthorized access, contact\n",
            "    NASA personnel.\n",
            "\n",
            "    Claims have been made on this news group about fraud and waste. None\n",
            "    have ever been substantiated to any significant degree. Readers\n",
            "    detecting Fraud, Waste, Abuse, or Mismanagement should contact the NASA\n",
            "    Inspector General (24-hours) at 800-424-9183 (can be anonymous) or write\n",
            "\n",
            "\tNASA\n",
            "\tInspector General\n",
            "\tP.O. Box 23089\n",
            "\tL'enfant Plaza Station\n",
            "\tWashington DC 20024\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 2800\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "747a3923-4b1c-4e2b-921d-4ebf2b271b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.        , 0.54488082, 0.49799339, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "04ddf3ca-0741-42d7-8bbb-00bb395f7834"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 2800,  5729,  9096, ...,  5802, 10187,  9314], dtype=int64)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QdJLHPJACvaj",
        "outputId": "926186cf-7d4c-4bd3-927b-ad00bf7f24f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'sci.space'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "daf534e5-b2a8-43d4-d05a-9c52b816cf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sci.space\n",
            "sci.space\n",
            "sci.space\n",
            "sci.space\n",
            "sci.space\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "TPM0thDaLk0R",
        "outputId": "bc7fdc3e-d912-4e0c-9d9e-33efc97b46fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "232ee2ce-e904-466e-be57-babc1f319029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "**2**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB.\n",
        "\n",
        "**3**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 1\n",
        "\n",
        "Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lista de documentos\n",
        "idx_list = [855, 4224, 6045, 1274, 2124]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Documento 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Similaridades: \n",
            "[1.         0.42192677 0.31493766 ... 0.         0.         0.        ]\n",
            "---------------------------------\n",
            "Documentos similares: \n",
            "[  855 10562   225 ...   473  9095  4021]\n",
            "---------------------------------\n",
            "Clase del documento original: \n",
            "talk.politics.guns\n",
            "---------------------------------\n",
            "Clase de los documentos similares: \n",
            "talk.politics.guns\n",
            "talk.politics.guns\n",
            "talk.politics.guns\n",
            "talk.politics.guns\n",
            "talk.politics.guns\n"
          ]
        }
      ],
      "source": [
        "idx = idx_list[0]\n",
        "\n",
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
        "\n",
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "sim = np.sort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Similaridades: \")\n",
        "print(sim)\n",
        "\n",
        "# y a qué documentos corresponden\n",
        "sim_docs = np.argsort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Documentos similares: \")\n",
        "print(sim_docs)\n",
        "\n",
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "# el documento original pertenece a la clase:\n",
        "main_class = newsgroups_train.target_names[y_train[idx]]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase del documento original: \")\n",
        "print(main_class)\n",
        "\n",
        "# y los 5 más similares son de las clases:\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase de los documentos similares: \")\n",
        "for i in mostsim:\n",
        "    print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Documento original:\n",
            "---------------------------------\n",
            "\n",
            "The point that I forgot to bring up here (and this has nothing to do with being\n",
            "a gang member or not) is that it is illegal to carry a concealed weapon in this\n",
            "area (or in the state of illinois for that matter).  This is not to say that\n",
            "people in Illinois don't carry concealed weapons illegaly but practicing like\n",
            "that when there are other people around wasn't too bright of an idea.\n",
            "\n",
            "\n",
            "I agree.      If you don't practice at all and carry a gun for self-defense you\n",
            "most likely would be in big trouble if a situation were to arise.\n",
            "\n",
            "---------------------------------\n",
            "Primer documento más similar: \n",
            "---------------------------------\n",
            "A couple of questions for you firearms law experts out there:  \n",
            "\n",
            "Question #1\n",
            "\n",
            "According to the NRA/ILA state firearms lawbook, in Wisconsin it is\n",
            "'unlawful for any person except a peace officer to go armed* with a \n",
            "\"concealed and dangerous weapon.\"  There is no statutory provision for\n",
            "obtaining a lixense or permit to carry a concealed weapon.'\n",
            "\n",
            "*  Jury instructions indicate that 'to go armed' one must have a firearm\n",
            "on one's person or within his immediate control and available for use.\n",
            "\n",
            "\n",
            "\n",
            "Does this mean that open carry is allowed?  If so, just how 'open' does it\n",
            "have to be?  Would an in the pants holster be considered concealing?  What\n",
            "if one had their jacket on and it partially covered the weapon?  Also,\n",
            "is there any way to be allowed to carry concealed, or is it just not allowed,\n",
            "period? \n",
            "\n",
            "Question #2\n",
            "\n",
            "As I understand it, in Evanston, IL, they have a ordinance banning handguns.\n",
            "Is there any way to get around this provision?  What would the penalty if\n",
            "you were found out be?  What if you used said handgun in a defensive shooting\n",
            "in your apartment there?  How would the city law apply to your impending \n",
            "trial for the shooting?\n",
            "Also, what is IL state law concerning short barreled weapons?  Short barreled\n",
            "shotgun is what I would be interested in if a handgun were not available, \n",
            "either that or a shortened 9mm carbine (ie Colt, Marlin).  \n",
            "One more thing, what is the chance of getting a CCW permit in IL without being\n",
            "rich or famous or related to the mayor?\n"
          ]
        }
      ],
      "source": [
        "# Vemos el documento original\n",
        "print(\"---------------------------------\")\n",
        "print('Documento original:')\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[idx])\n",
        "\n",
        "# Leemos el documento más similar (después del original) a modo de verificación\n",
        "print(\"\")\n",
        "print(\"---------------------------------\")\n",
        "print(\"Primer documento más similar: \")\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[mostsim[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Documento 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Similaridades: \n",
            "[1.         0.33213845 0.32931617 ... 0.         0.         0.        ]\n",
            "---------------------------------\n",
            "Documentos similares: \n",
            "[ 4224  8211  2328 ... 10266  7683  3782]\n",
            "---------------------------------\n",
            "Clase del documento original: \n",
            "talk.politics.misc\n",
            "---------------------------------\n",
            "Clase de los documentos similares: \n",
            "talk.politics.misc\n",
            "alt.atheism\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "sci.crypt\n"
          ]
        }
      ],
      "source": [
        "idx = idx_list[1]\n",
        "\n",
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
        "\n",
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "sim = np.sort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Similaridades: \")\n",
        "print(sim)\n",
        "\n",
        "# y a qué documentos corresponden\n",
        "sim_docs = np.argsort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Documentos similares: \")\n",
        "print(sim_docs)\n",
        "\n",
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "# el documento original pertenece a la clase:\n",
        "main_class = newsgroups_train.target_names[y_train[idx]]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase del documento original: \")\n",
        "print(main_class)\n",
        "\n",
        "# y los 5 más similares son de las clases:\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase de los documentos similares: \")\n",
        "for i in mostsim:\n",
        "    print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Documento original:\n",
            "---------------------------------\n",
            "# #They believe that they have a right to FORCE people to hire them,\n",
            "# #rent to them, and do business with them, regardless of the feelings\n",
            "# #or beliefs of the other person.\n",
            "# \n",
            "# Cramer, you are off your target again.  The law *forces* no one to obey\n",
            "# it.  At every point any individual may stand up and say *this law\n",
            "# sucks*.  Even you could say this.  Gay men and women have not *forced*\n",
            "\n",
            "You mean they passed a law that does nothing at all?  No enforcement\n",
            "mechanisms?  As usual, you are wrong.\n",
            "\n",
            "# any off this.  Changes in the law have been brought about by\n",
            "# democratic* processes, those same processes are the ones that protect\n",
            "# you from certain abuses.\n",
            "\n",
            "Yeah, right.  I guess the next time a homosexual complains about\n",
            "sodomy laws, I can just echo your stupidity about \"democratic\n",
            "processes\" and he won't have any basis for complaint.\n",
            "\n",
            "# #I must admit that I never understood why it is referred to as an \n",
            "# #abomination, until I started to read soc.motss, and started finding\n",
            "# #evidence that homosexuality is a response to child molestation --\n",
            "# #which is disproportionately done by homosexuals.  (Just to make\n",
            "# #Brian Kane happy -- 30% of molestation is done by homosexuals and\n",
            "# #bisexuals, but it is possible that this is because homosexual/bisexual\n",
            "# #molesters have far more victims than heterosexual molesters.)\n",
            "# \n",
            "# No it isn't.  No it isn't. No it isn't and it depends on the subset\n",
            "# (note *subset*) of abuse you look at.\n",
            "\n",
            "Repeating it three times makes it more correct?\n",
            "\n",
            "# #Clayton E. Cramer {uunet,pyramid}!optilink!cramer  My opinions, all mine!\n",
            "# #Relations between people to be by mutual consent, or not at all.\n",
            "# \n",
            "# * Xavier Gallagher*************************** Play  ***************************\n",
            "\n",
            "---------------------------------\n",
            "Primer documento más similar: \n",
            "---------------------------------\n",
            ": I\n",
            ": |> Jim,\n",
            ": |> \n",
            ": |> I always thought that homophobe was only a word used at Act UP\n",
            ": |> rallies, I didn't beleive real people used it. Let's see if we agree\n",
            ": |> on the term's definition. A homophobe is one who actively and\n",
            ": |> militantly attacks homosexuals because he is actually a latent\n",
            ": |> homosexual who uses his hostility to conceal his true orientation.\n",
            ": |> Since everyone who disapproves of or condemns homosexuality is a\n",
            ": |> homophobe (your implication is clear), it must necessarily follow that\n",
            ": |> all men are latent homosexuals or bisexual at the very least.\n",
            ": |> \n",
            ": \n",
            ": Crap crap crap crap crap.  A definition of any type of 'phobe comes from\n",
            ": phobia = an irrational fear of.  Hence a homophobe (not only in ACT UP meetings,\n",
            ": the word is apparently in general use now.  Or perhaps it isn't in the bible?  \n",
            ": Wouldst thou prefer if I were to communicate with thou in bilespeak?)\n",
            ": \n",
            ": Does an arachnophobe have an irrational fear of being a spider?  Does an\n",
            ": agoraphobe have an irrational fear of being a wide open space?  Do you\n",
            ": understand English?\n",
            ": \n",
            ": Obviously someone who has  phobia will react to it.  They will do their best\n",
            ": to avoid it and if that is not possible they will either strike out or\n",
            ": run away.  Or do gaybashings occur because of natural processes?  People\n",
            ": who definately have homophobia will either run away from gay people or\n",
            ": cause them (or themselves) violence.\n",
            ": \n",
            "\n",
            "Isn't that what I said ...\n",
            "What are you taking issue with here, your remarks are merely\n",
            "parenthetical to mine and add nothing useful.\n",
            "\n",
            ": [...]\n",
            ": \n",
            ": |> It would seem odd if homosexuality had any evolutionary function\n",
            ": |> (other than limiting population growth) since evolution only occurs\n",
            ": |> when the members of one generation pass along their traits to\n",
            ": |> subsequent generations. Homosexuality is an evolutionary deadend. If I\n",
            ": |> take your usage of the term, homophobe, in the sense you seem to\n",
            ": |> intend, then all men are really homosexual and evolution of our\n",
            ": |> species at least, is going nowhere.\n",
            ": |> \n",
            ": \n",
            ": So *every* time a man has sex with a woman they intend to produce children?\n",
            ": Hmm...no wonder the world is overpopulated.  Obviously you keep to the\n",
            ": Monty Python song:  \"Every sperm is sacred\".  And if, as *you* say, it has\n",
            ": a purpose as a means to limit population growth then it is, by your own \n",
            ": arguement, natural.\n",
            "\n",
            "Consider the context, I'm talking about an evolutionary function. One\n",
            "of the most basic requirements of evolution is that members of a\n",
            "species procreate, those who don't have no purpose in that context.\n",
            "\n",
            ": \n",
            ": |> Another point is that if the offspring of each generation is to\n",
            ": |> survive, the participation of both parents is necessary - a family must\n",
            ": |> exist, since homosexuals do not reproduce, they cannot constitute a\n",
            ": |> family. Since the majority of humankind is part of a family,\n",
            ": |> homosexuality is an evolutionary abberation, contrary to nature if you\n",
            ": |> will.\n",
            ": |> \n",
            ": \n",
            ": Well if that is true, by your own arguements homosexuals would have \n",
            ": vanished *years* ago due to non-procreation.  Also the parent from single\n",
            ": parent families should put the babies out in the cold now, cos they must,\n",
            ": by your arguement, die.\n",
            "\n",
            "By your argument, homosexuality is genetically determined. As to your\n",
            "second point, you prove again that you have no idea what context\n",
            "means. I am talking about evolution, the preservation of the species,\n",
            "the fundamental premise of the whole process.\n",
            ": \n",
            ": |> But it gets worse. Since the overwhelming majority of people actually\n",
            ": |> -prefer- a heterosexual relationship, homosexuality is a social\n",
            ": |> abberation as well. The homosexual eschews the biological imperative\n",
            ": |> to reproduce and then the social imperative to form and participate in\n",
            ": |> the most fundamental social element, the family. But wait, there's\n",
            ": |> more.\n",
            ": |> \n",
            ": \n",
            ": Read the above.  I expect you to have at least ten children by now, with\n",
            ": the family growing.  These days sex is less to do with procreation (admittedly\n",
            ": without it there would be no-one) but more to do with pleasure.  In pre-pill\n",
            ": and pre-condom days, if you had sex there was the chance of producing children.\n",
            ": These days is just ain't true!  People can decide whether or not to have \n",
            ": children and when.  Soon they will be able to choose it's sex &c (but that's \n",
            ": another arguement...) so it's more of a \"lifestyle\" decision.  Again by\n",
            ": your arguement, since homosexuals can not (or choose not) to reproduce they must\n",
            ": be akin to people who decide to have sex but not children.  Both are \n",
            ": as \"unnatural\" as each other.\n",
            "\n",
            "Yet another non-sequitur. Sex is an evolutionary function that exists\n",
            "for procreation, that it is also recreation is incidental. That\n",
            "homosexuals don't procreate means that sex is -only- recreation and\n",
            "nothing more; they serve no -evolutionary- purpose.\n",
            "\n",
            ": \n",
            ": |> Since homosexuals have come out the closet and have convinced some\n",
            ": |> policy makers that they have civil rights, they are now claiming that\n",
            ": |> their sexuality is a preference, a life-style, an orientation, a\n",
            ": |> choice that should be protected by law. Now if homosexuality is a mere\n",
            ": |> choice and if it is both contrary to nature and anti-social, then it\n",
            ": |> is a perverse choice; they have even less credibility than before they\n",
            ": |> became prominent. \n",
            ": |> \n",
            ": \n",
            ": People are people are people.  Who are you to tell anyone else how to live\n",
            ": their life?  Are you god(tm)?  If so, fancy a date?\n",
            "\n",
            "Here's pretty obvious dodge, do you really think you've said anything\n",
            "or do you just feel obligated to respond to every statement? I am not\n",
            "telling anyone anything, I am demonstrating that there are arguments\n",
            "against the practice of homosexuality (providing it's a merely an\n",
            "alternate lifestlye) that are not homophobic, that one can reasonably\n",
            "call it perverse in a context even a atheist can understand. I realize\n",
            "of course that this comes dangerously close to establishing  a value,\n",
            "and that atheists are compelled to object on that basis, but if you\n",
            "are to be consistent, you have no case in this regard.\n",
            ": \n",
            ": |> To characterize any opposition to homosexuality as homophobic is to\n",
            ": |> ignore some very compelling arguments against the legitimization of\n",
            ": |> the homosexual \"life-style\". But since the charge is only intended to\n",
            ": |> intimidate, it's really just demogoguery and not to be taken\n",
            ": |> seriously. Fact is, Jim, there are far more persuasive arguments for\n",
            ": |> suppressing homosexuality than those given, but consider this a start.\n",
            ": |> \n",
            ": \n",
            ": Again crap.  All your arguments are based on outdated ideals.  Likewise the\n",
            ": bible.  Would any honest Christian condemn the ten generations spawned by\n",
            ": a \"bastard\" to eternal damnation?  Or someone who crushes his penis (either\n",
            ": accidently or not..!).  Both are in Deuteronomy.\n",
            "\n",
            "I'm sure your comment pertains to something, but you've disguised it\n",
            "so well I can't see what. Where did I mention ideals, out-dated or\n",
            "otherwise? Your arguments are very reactionary; do you have anything\n",
            "at all to contribute?\n",
            "\n",
            ": \n",
            ": |> As to why homosexuals should be excluded from participation in\n",
            ": |> scouting, the reasons are the same as those used to restrict them from\n",
            ": |> teaching; by their own logic, homosexuals are deviates, social and\n",
            ": |> biological. Since any adult is a role model for a child, it is\n",
            ": |> incumbent on the parent to ensure that the child be isolated from\n",
            ": |> those who would do the child harm. In this case, harm means primarily\n",
            ": |> social, though that could be extended easily enough.\n",
            ": |> \n",
            ": |> \n",
            ": \n",
            ": You show me *anyone* who has sex in a way that everyone would describe as\n",
            ": normal, and will take of my hat (Puma baseball cap) to you.  \"One man's meat\n",
            ": is another man's poison\"!\n",
            ": \n",
            "\n",
            "What has this got to do with anything? Would you pick a single point\n",
            "that you find offensive and explain your objections, I would really\n",
            "like to believe that you can discuss this issue intelligibly.\n"
          ]
        }
      ],
      "source": [
        "# Vemos el documento original\n",
        "print(\"---------------------------------\")\n",
        "print('Documento original:')\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[idx])\n",
        "\n",
        "# Leemos el documento más similar (después del original) a modo de verificación\n",
        "print(\"\")\n",
        "print(\"---------------------------------\")\n",
        "print(\"Primer documento más similar: \")\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[mostsim[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Documento 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Similaridades: \n",
            "[1.         0.57423947 0.26629149 ... 0.         0.         0.        ]\n",
            "---------------------------------\n",
            "Documentos similares: \n",
            "[6045 6004 8107 ... 3939 9610 4386]\n",
            "---------------------------------\n",
            "Clase del documento original: \n",
            "comp.os.ms-windows.misc\n",
            "---------------------------------\n",
            "Clase de los documentos similares: \n",
            "comp.os.ms-windows.misc\n",
            "comp.sys.ibm.pc.hardware\n",
            "comp.os.ms-windows.misc\n",
            "comp.sys.mac.hardware\n",
            "comp.graphics\n"
          ]
        }
      ],
      "source": [
        "idx = idx_list[2]\n",
        "\n",
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
        "\n",
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "sim = np.sort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Similaridades: \")\n",
        "print(sim)\n",
        "\n",
        "# y a qué documentos corresponden\n",
        "sim_docs = np.argsort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Documentos similares: \")\n",
        "print(sim_docs)\n",
        "\n",
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "# el documento original pertenece a la clase:\n",
        "main_class = newsgroups_train.target_names[y_train[idx]]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase del documento original: \")\n",
        "print(main_class)\n",
        "\n",
        "# y los 5 más similares son de las clases:\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase de los documentos similares: \")\n",
        "for i in mostsim:\n",
        "    print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Documento original:\n",
            "---------------------------------\n",
            "\n",
            "\n",
            "    >Version 1.3 drivers are due to be release by Cirrus soon.\n",
            "    >Unfortunately, their not available via FTP, you have to dial\n",
            "    >up their BBS in the USA.  I do this from NZ using a 14.4k modem\n",
            "    >to cut down on phone bills.  It took me around 7 minutes to \n",
            "    >download the v1.2 driver.\n",
            "\n",
            "\tCould you please upload to any of the ftp sites (such as\n",
            "\tftp.ciaca.indiana.edu) and announce it here? This will benefit\n",
            "\tpeople does not have access to their BBS in USA (like me :-))?\n",
            "\n",
            "\tThanks a lot.\n",
            "\n",
            "---------------------------------\n",
            "Primer documento más similar: \n",
            "---------------------------------\n",
            "Could anybody please provide me a copy of the Windows 3.1 drivers and grabbers\n",
            "from Orchid Technologies for use with their ProDesigner IIs ISA video card? Currently I do not have access to a modem to dial out to Orchid BBS.\n",
            "If you can help me, please do any of the following, wichever is most convenient\n",
            "to you:\n",
            "\n",
            "1)\n",
            "Copy the binary files to a directory readable by any user in any cell of the\n",
            "Andrew File System\n",
            "\n",
            "2)\n",
            "Upload the binary files to an anonymous FTP site (where allowed).\n",
            "\n",
            "3)\n",
            "uuencode the files and send them to me by electronic mail.\n",
            "\n",
            "Please notify me by electronic mail at\n",
            "towwang@caen.engin.umich.edu\n",
            "\n",
            "Thanks in advance.\n"
          ]
        }
      ],
      "source": [
        "# Vemos el documento original\n",
        "print(\"---------------------------------\")\n",
        "print('Documento original:')\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[idx])\n",
        "\n",
        "# Leemos el documento más similar (después del original) a modo de verificación\n",
        "print(\"\")\n",
        "print(\"---------------------------------\")\n",
        "print(\"Primer documento más similar: \")\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[mostsim[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Documento 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Similaridades: \n",
            "[1.         0.55560698 0.39695861 ... 0.         0.         0.        ]\n",
            "---------------------------------\n",
            "Documentos similares: \n",
            "[ 1274  5872   367 ...   340 10639 10545]\n",
            "---------------------------------\n",
            "Clase del documento original: \n",
            "comp.windows.x\n",
            "---------------------------------\n",
            "Clase de los documentos similares: \n",
            "comp.windows.x\n",
            "comp.windows.x\n",
            "comp.windows.x\n",
            "comp.windows.x\n",
            "comp.windows.x\n"
          ]
        }
      ],
      "source": [
        "idx = idx_list[3]\n",
        "\n",
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
        "\n",
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "sim = np.sort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Similaridades: \")\n",
        "print(sim)\n",
        "\n",
        "# y a qué documentos corresponden\n",
        "sim_docs = np.argsort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Documentos similares: \")\n",
        "print(sim_docs)\n",
        "\n",
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "# el documento original pertenece a la clase:\n",
        "main_class = newsgroups_train.target_names[y_train[idx]]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase del documento original: \")\n",
        "print(main_class)\n",
        "\n",
        "# y los 5 más similares son de las clases:\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase de los documentos similares: \")\n",
        "for i in mostsim:\n",
        "    print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Documento original:\n",
            "---------------------------------\n",
            "Hello Motif World,\n",
            "\n",
            "a few days ago I posted my announcement for an update of Motif++. I got\n",
            "several requests to send the bindings per e-mail, and I know of several people\n",
            "who have been using Motif++, and there are probably a number of people I am\n",
            "not aware of who are also using Motif++.\n",
            "\n",
            "My question is:\n",
            "\n",
            "How many people 'out there' would be interested to join a mailing-list, where\n",
            "people can ask questions about Motif++, swap stories, and give new ideas about\n",
            "new directions and improvements for the bindings. This would benefit the\n",
            "user-community, as well as give me more insight in what people would like to\n",
            "see added to Motif++. Motif++ is still very much a voluntary project, and this\n",
            "way I can make a list of priorities, in what order things should be added, or\n",
            "changed.\n",
            "\n",
            "If you're interested in joining such a mailing-list, please take the time to\n",
            "reply to this message, and tell me so. When there is sufficient interest, say\n",
            "about 20 people or more, a mailing-list will be set up at my site, and I will\n",
            "post the announcement of the newly-created list to this and other newsgroups.\n",
            "\n",
            "---------------------------------\n",
            "Primer documento más similar: \n",
            "---------------------------------\n",
            "\n",
            "  Let me add another of my concerns: Yes, I can buy a port of Motif for \"cheap\",\n",
            "but I cannot get the source for \"cheap\", hence I am limited to using whatever X\n",
            "libraries the Motif port was compiled against (at least with older versions of\n",
            "Motif. I have been told that Motif 1.2 can be used with any X, but I have not\n",
            "seen it myself).\n",
            "\n",
            "  Currently, I have X11R5 running on eight different unix platforms, of which\n",
            "only three came with Motif. On those three, I am unable to use the X11R5\n",
            "libraries to build Motif clients, because I get link errors between the\n",
            "vendor-supplied port of Motif and my X11R5. I anticipate having this same\n",
            "problem when X11R6 becomes available.\n",
            "\n",
            "  The result is that I cannot build Motif clients that rely on X11R5, since I do\n",
            "not have Motif compiled under X11R5. True, I could buy another port of Motif,\n",
            "but that sort of ruins the whole idea of \"free\", doesn't it?\n",
            "\n",
            "    Cheers,\n",
            "\n",
            "    Tom McConnell\n"
          ]
        }
      ],
      "source": [
        "# Vemos el documento original\n",
        "print(\"---------------------------------\")\n",
        "print('Documento original:')\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[idx])\n",
        "\n",
        "# Leemos el documento más similar (después del original) a modo de verificación\n",
        "print(\"\")\n",
        "print(\"---------------------------------\")\n",
        "print(\"Primer documento más similar: \")\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[mostsim[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Documento 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Similaridades: \n",
            "[1.         0.84995459 0.42025854 ... 0.         0.         0.        ]\n",
            "---------------------------------\n",
            "Documentos similares: \n",
            "[2124 4915 7130 ... 2424 3258 9917]\n",
            "---------------------------------\n",
            "Clase del documento original: \n",
            "sci.med\n",
            "---------------------------------\n",
            "Clase de los documentos similares: \n",
            "sci.med\n",
            "sci.med\n",
            "sci.med\n",
            "sci.med\n",
            "talk.politics.guns\n"
          ]
        }
      ],
      "source": [
        "idx = idx_list[4]\n",
        "\n",
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]\n",
        "\n",
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "sim = np.sort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Similaridades: \")\n",
        "print(sim)\n",
        "\n",
        "# y a qué documentos corresponden\n",
        "sim_docs = np.argsort(cossim)[::-1]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Documentos similares: \")\n",
        "print(sim_docs)\n",
        "\n",
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "# el documento original pertenece a la clase:\n",
        "main_class = newsgroups_train.target_names[y_train[idx]]\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase del documento original: \")\n",
        "print(main_class)\n",
        "\n",
        "# y los 5 más similares son de las clases:\n",
        "print(\"---------------------------------\")\n",
        "print(\"Clase de los documentos similares: \")\n",
        "for i in mostsim:\n",
        "    print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Documento original:\n",
            "---------------------------------\n",
            "\n",
            "Hismanal (astemizole) is most definitely linked to weight gain.\n",
            "It really is peculiar that some antihistamines have this effect,\n",
            "and even more so an antihistamine like astemizole which purportedly\n",
            "doesn't cross the blood-brain barrier and so tends not to cause\n",
            "drowsiness.\n",
            "\n",
            "\n",
            "---------------------------------\n",
            "Primer documento más similar: \n",
            "---------------------------------\n",
            "\n",
            "So antihistamines can cause weight gain.  NOW they tell me. :-)\n",
            "Is there any way to find out which do & which don't?  My doctor\n",
            "obviously is asleep at the wheel.\n",
            "\n",
            "The original poster mentioned fatigue.  I had that too, but it was\n",
            "mostly due to the really bizarre dreams I was having -- I wasn't getting\n",
            "any rest.  My doctor said that was a common reaction.  If astemizole\n",
            "doesn't cross the blood-brain barrier, how does it cause that side\n",
            "effect?  Any ideas?\n",
            "\n",
            "-- \n"
          ]
        }
      ],
      "source": [
        "# Vemos el documento original\n",
        "print(\"---------------------------------\")\n",
        "print('Documento original:')\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[idx])\n",
        "\n",
        "# Leemos el documento más similar (después del original) a modo de verificación\n",
        "print(\"\")\n",
        "print(\"---------------------------------\")\n",
        "print(\"Primer documento más similar: \")\n",
        "print(\"---------------------------------\")\n",
        "print(newsgroups_train.data[mostsim[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 2\n",
        "\n",
        "Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MultinomialNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "tfidfvect_multi = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF) y transformar directamente los datos\n",
        "X_train_multi = tfidfvect_multi.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se definen varios parametros del modelo\n",
        "parametros = {\n",
        "    'alpha': [0.01, 0.1, 0.5, 1.0], # Default es 1.0 -> Parámetro de suavizado de Laplace\n",
        "    'fit_prior': [True, False] # Default es True -> Aprende las probabilidades a priori de las clases? Sino, usa probabilidad uniforme\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros con MultinomialNB: {'alpha': 0.01, 'fit_prior': False}\n",
            "Mejor F1-score con MultinomialNB: 0.6876839515570421\n"
          ]
        }
      ],
      "source": [
        "clf_multi = GridSearchCV(MultinomialNB(), parametros, cv=5, scoring='f1_macro')\n",
        "clf_multi.fit(X_train_multi, y_train)\n",
        "best_params_multi = clf_multi.best_params_\n",
        "clf_multi_best = clf_multi.best_estimator_\n",
        "\n",
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test_multi = tfidfvect_multi.transform(newsgroups_test.data)\n",
        "y_test_multi = newsgroups_test.target\n",
        "\n",
        "# Evaluamos el modelo con los mejores parametros\n",
        "y_pred_multi = clf_multi_best.predict(X_test_multi)\n",
        "\n",
        "# Obtenemos el F1-score con \"macro\" por ser mejor para datasets desbalanceados\n",
        "f1_multi = f1_score(y_test_multi, y_pred_multi, average='macro')\n",
        "\n",
        "print(f\"Mejores parámetros con MultinomialNB: {best_params_multi}\")\n",
        "print(f\"Mejor F1-score con MultinomialNB: {f1_multi}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ComplementNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "tfidfvect_cnb = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF) y transformar directamente los datos\n",
        "X_train_cnb= tfidfvect_cnb.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros con ComplementNB: {'alpha': 0.1, 'fit_prior': True}\n",
            "Mejor F1-score con ComplementNB: 0.6919194498508968\n"
          ]
        }
      ],
      "source": [
        "clf_cnb = GridSearchCV(ComplementNB(), parametros, cv=5, scoring='f1_macro')\n",
        "clf_cnb.fit(X_train_cnb, y_train)\n",
        "best_params_cnb = clf_cnb.best_params_\n",
        "clf_cnb_best = clf_cnb.best_estimator_\n",
        "\n",
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test_cnb = tfidfvect_cnb.transform(newsgroups_test.data)\n",
        "y_test_cnb = newsgroups_test.target\n",
        "\n",
        "# Evaluamos el modelo con los mejores parametros\n",
        "y_pred_cnb = clf_cnb_best.predict(X_test_cnb)\n",
        "\n",
        "# Obtenemos el F1-score con \"macro\" por ser mejor para datasets desbalanceados\n",
        "f1_cnb = f1_score(y_test_cnb, y_pred_cnb, average='macro')\n",
        "\n",
        "print(f\"Mejores parámetros con ComplementNB: {best_params_cnb}\")\n",
        "print(f\"Mejor F1-score con ComplementNB: {f1_cnb}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Comentarios**\n",
        "\n",
        "- Ya solo con agregar los \"Stop Words\" del inglés se mejora el score del modelo.\n",
        "- La diferencia en el score no es tanta entre ambos modelos, pero ComplementNB es mejor en este caso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parte 3\n",
        "Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quitamos las stopwords\n",
        "tfidfvect_t = TfidfVectorizer(stop_words='english')\n",
        "X_train_= tfidfvect_t.fit_transform(newsgroups_train.data)\n",
        "\n",
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect_t.vocabulary_.items()}\n",
        "\n",
        "\n",
        "# Se transpone la matriz de entrenamiento\n",
        "X_train_T = X_train_.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indice de la palabra 'image': 48959\n",
            "Indice de la palabra 'god': 43733\n",
            "Indice de la palabra 'house': 47314\n",
            "Indice de la palabra 'space': 83871\n",
            "Indice de la palabra 'car': 25717\n"
          ]
        }
      ],
      "source": [
        "# Se seleccionan las palabras y se obtiene su indice\n",
        "\n",
        "palabras = ['image', 'god', 'house', 'space', 'car']\n",
        "word_index = []\n",
        "\n",
        "for palabra in palabras:\n",
        "    idx = tfidfvect_t.vocabulary_[palabra]\n",
        "    print(f\"Indice de la palabra '{palabra}': {idx}\")\n",
        "    word_index.append(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "Palabra: image\n",
            "---------------------------------\n",
            "Palabras similares: ['morphological', 'vista', 'ffts', 'histogram', 'nimh']\n",
            "Similitud: [0.27452917 0.27262271 0.27262271 0.26931519 0.26091651]\n",
            "\n",
            "---------------------------------\n",
            "Palabra: god\n",
            "---------------------------------\n",
            "Palabras similares: ['jesus', 'bible', 'christ', 'faith', 'existence']\n",
            "Similitud: [0.28062629 0.27639079 0.26683025 0.25928239 0.25887389]\n",
            "\n",
            "---------------------------------\n",
            "Palabra: house\n",
            "---------------------------------\n",
            "Palabras similares: ['senate', 'white', 'cpr', 'veto', 'miyazawa']\n",
            "Similitud: [0.26694565 0.25493653 0.24317101 0.21345921 0.20213188]\n",
            "\n",
            "---------------------------------\n",
            "Palabra: space\n",
            "---------------------------------\n",
            "Palabras similares: ['nasa', 'shuttle', 'seds', 'enfant', 'exploration']\n",
            "Similitud: [0.32793997 0.2902489  0.28490722 0.26941108 0.23983273]\n",
            "\n",
            "---------------------------------\n",
            "Palabra: car\n",
            "---------------------------------\n",
            "Palabras similares: ['cars', 'criterium', 'dealer', 'civic', 'owner']\n",
            "Similitud: [0.18975943 0.17321434 0.17320567 0.17131631 0.16443844]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for palabra_idx in word_index:\n",
        "    # midamos la similaridad coseno con todos los términos de train\n",
        "    terms_cossim = cosine_similarity(X_train_T[palabra_idx], X_train_T)[0]\n",
        "    print(\"---------------------------------\")\n",
        "    print(f\"Palabra: {idx2word[palabra_idx]}\")\n",
        "    print(\"---------------------------------\")\n",
        "    # los 5 términos más similares:\n",
        "    terms_mostsim_idx = np.argsort(terms_cossim)[::-1][1:6]\n",
        "    words_mostsim = [idx2word[i] for i in terms_mostsim_idx]\n",
        "    terms_mostsim_cos = np.sort(terms_cossim)[::-1][1:6]\n",
        "    print(f\"Palabras similares: {words_mostsim}\")\n",
        "    print(f\"Similitud: {terms_mostsim_cos}\")\n",
        "    print(\"\")\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Estudio de las palabras y sus similares:\n",
        "\n",
        "**image**:\n",
        "- ``morphological``: tiene sentido.\n",
        "- ``vista``: puede relacionarse a una imagen.\n",
        "- ``ffts``: puede tratarse de Fast Fourier Transforms (FTTs) que se asocian a imágenes.\n",
        "- ``nimh``: no parece tener sentido en este caso, podría ser una palabra no completa.\n",
        "\n",
        "**god**:\n",
        "- En este caso, claramente todas las palabras ``['jesus', 'bible', 'christ', 'faith', 'existence']`` tienen sentido y relación con la palabra \"Dios\".\n",
        "\n",
        "**house**:\n",
        "- ``['senate', 'white', 'veto']`` son todas palabras que pueden relacionarse con política estadounidense, cuyas instituciones utilizan la palabra \"Hause\" para sus nombres.\n",
        "- ``['cpr', 'miyazawa']``: estas palabras no parecen tener mucho sentido en su relación con \"House\".\n",
        "\n",
        "**space**\n",
        "- ``['nasa', 'shuttle', 'exploration']``: todas estas palabras pueden relacionarse fácilmente con la palabra \"space\".\n",
        "- ``seds``: esta palabra puede relacionarse a una organización estudiantil llamada SEDS que promueve la exploración espacial.\n",
        "- ``enfant``: esta palabra parece fuera de lugar en este conjunto.\n",
        "\n",
        "**car**\n",
        "- ``['cars', 'dealer', 'civic', 'owner']``: todas estas palabras pueden asociarse a carros (en este caso 'civi' se refiere al Honda Civic).\n",
        "- ``criterium``: Esta palabra no parece tener mucho sentido en este conjunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Potencial mejora\n",
        "\n",
        "- Buscar los 5 documentos más relevantes para las palabras que no parecen tener relación y encontrar sus categorías. Asociar la categoría a la cantidad de ocurrencias de la palabra en dicha categoría. De este modo se puede tratar de encontrar una exlicación a la relación entre las palabras.\n",
        "- Leer algunos documentos que contengan la palabra original, la palabra que no parece encajar en la categoría y alguna palabra que sí parece correcta. Esto puede ayudar a entender la relación entre ellas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
